{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "85cfb99e-08fa-485d-8ee2-a942cc071255",
   "metadata": {},
   "source": [
    "# RAG (Retrieval Augumented Generation) - Example\n",
    "RAG is a mechanism of retrieving and incorporating external information before LLM generates a response. The external information has to be vector embeddings usually stored in a vector database such as pinecore, opensearch etc... This techinique is very cost and time effective comparing with fine tuning model in which the LLM model will need to be re-trained.\n",
    "\n",
    "There are ML models available which helps creating embeddings from text or images or both(multimodel models).\n",
    "\n",
    "In this example, we are going to expore a typical workflow of RAG.\n",
    "\n",
    "- Step 1: Read document for embedding\n",
    "- Step 2: Create embedding using amazon embedding model - amazon.titan-embed-text-v2:0\n",
    "- Step 3: Create a dataframe to store the embeddings (mock vector database)\n",
    "- Step 4: Retrieve similar document for a prompt - Using Cosign Similarity (prompt and embedding)\n",
    "- Step 5: Create prompt for the LLM along with the context emmbedding\n",
    "- Step 6: Generate content using the Meta Llama model - ``"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01001d91-1e1f-4386-8497-b525faaaebd7",
   "metadata": {},
   "source": [
    "## Step 1: Read documents for embedding\n",
    "We will use Pypdf to read a PDF document. For re-usability purpose, lets create a function to read a pdf file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6dfb06d5-9c17-4343-9f61-6992cc95295d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.python.org/simple\n",
      "Requirement already satisfied: pypdf in /Users/nila/Documents/Learning.nosync/AI/Nila-AI-ML-Projects/bedrock_samples/env/lib/python3.13/site-packages (5.5.0)\n"
     ]
    }
   ],
   "source": [
    "# Use pypdf to read PDF document as string\n",
    "# Install pypdf if not exists already\n",
    "!pip install pypdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81afba6e-c88d-4f2e-87f6-7e26beae030a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pypdf import PdfReader\n",
    "\n",
    "#Lets create a function to read PDF pages\n",
    "\n",
    "def as_text(pdf_file_name):\n",
    "    reader = PdfReader(pdf_file_name)\n",
    "    print(f'Number of pages {len(reader.pages)}')\n",
    "    # Lets read only the first page\n",
    "    page = reader.pages[0]\n",
    "    return page.extract_text()\n",
    "\n",
    "#print(as_text('sports_news.pdf'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a87b753f-f10a-47bc-a0bd-a629a491f747",
   "metadata": {},
   "source": [
    "## Step 2: Create embedding using amazon embedding model\n",
    "We are going to use Amazon embedding model - amazon.titan-embed-text-v2:0\n",
    "\n",
    "Request format for the model is as below,\n",
    "```\n",
    "{\n",
    "    \"inputText\": string,\n",
    "    \"dimensions\": int,\n",
    "    \"normalize\": boolean,\n",
    "    \"embeddingTypes\": list\n",
    "}\n",
    "```\n",
    "Response format,\n",
    "```\n",
    "{\n",
    "    \"embedding\": [float, float, ...],\n",
    "    \"inputTextTokenCount\": int,\n",
    "    \"embeddingsByType\": {\"binary\": [int,..], \"float\": [float,...]}\n",
    "}\n",
    "```\n",
    "Reference documentation - https://docs.aws.amazon.com/bedrock/latest/userguide/model-parameters-titan-embed-text.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "358651c6-1838-460a-b41c-19d14933f22d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure AWS environment\n",
    "# Below method is NOT recommended for public sharing or deployments to environments\n",
    "import os\n",
    "\n",
    "os.environ['AWS_ACCESS_KEY_ID'] = 'your key id'\n",
    "os.environ['AWS_SECRET_ACCESS_KEY'] = 'your secret'\n",
    "\n",
    "os.environ['AWS_DEFAULT_REGION'] = 'us-east-1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "63d83516-7052-442d-9f79-d0f9e000e3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets use boto3 to connect to bedrock APIs to access the model\n",
    "import boto3\n",
    "# Use json to build the request\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f9b15a5-7e96-43f0-8539-16cec8ebc3c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For reuseability lets create a function\n",
    "def get_text_embedding(text_for_embedding):\n",
    "    bedrock_runtime = boto3.client(service_name='bedrock-runtime', region_name='us-east-1')\n",
    "    req = json.dumps({'inputText':text_for_embedding})\n",
    "    response = bedrock_runtime.invoke_model(body=req, modelId='amazon.titan-embed-text-v2:0')\n",
    "    response_body = json.loads(response.get('body').read())\n",
    "    return response_body['embedding']\n",
    "#print(get_text_embedding(as_text('sports_news.pdf')))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99ee33dd-7766-4cf4-ab85-d0e08efcc1f7",
   "metadata": {},
   "source": [
    "## Step 3: Create a data frame to store the embeddings (mock vector database)¶\n",
    "In production like environments, the embeddings will be stored in a vector database. For the purpose of demonstration, lets create a mock vector database using pandas dataframe. The dataframe need to have the below,\n",
    "\n",
    "- Identifier/title\n",
    "- Text\n",
    "- Embedding\n",
    "-------------------------------\n",
    "identifier | Text | Embedding\n",
    "-------------------------------\n",
    "       |               |\n",
    "       |               |\n",
    "       |               |       \n",
    "-------------------------------\n",
    "\n",
    "Lets use the functions that we have created on steps 1 and 2 to create the mock vector database.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ff9b33ec-f84a-402c-aef8-a1f380c47135",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ignoring wrong pointing object 6 0 (offset 0)\n",
      "Ignoring wrong pointing object 6 0 (offset 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of pages 1\n",
      "Number of pages 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>identifier</th>\n",
       "      <th>text</th>\n",
       "      <th>embeddings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cricket-news</td>\n",
       "      <td>Legendary India batter Virat Kohli has announc...</td>\n",
       "      <td>[-0.03001970238983631, 0.026122447103261948, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>uk-employment-news</td>\n",
       "      <td>The UK's job market has continued to weaken wi...</td>\n",
       "      <td>[0.023377733305096626, 0.07752429693937302, -0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           identifier                                               text  \\\n",
       "0        cricket-news  Legendary India batter Virat Kohli has announc...   \n",
       "1  uk-employment-news  The UK's job market has continued to weaken wi...   \n",
       "\n",
       "                                          embeddings  \n",
       "0  [-0.03001970238983631, 0.026122447103261948, 0...  \n",
       "1  [0.023377733305096626, 0.07752429693937302, -0...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use pandas to create dataframe\n",
    "import pandas as pd\n",
    "\n",
    "sports_news = as_text('sports_news.pdf')\n",
    "employment_news = as_text('uk-job-market-news.pdf')\n",
    "data = {'identifier':['cricket-news', 'uk-employment-news'],\n",
    "       'text':[sports_news,employment_news],\n",
    "        'embeddings':[get_text_embedding(sports_news), get_text_embedding(employment_news)]\n",
    "       }\n",
    "vector_db = pd.DataFrame(data)\n",
    "vector_db"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "067a079c-d357-4bf0-ab1e-2e7d40204a90",
   "metadata": {},
   "source": [
    "## Step 4: Retrieve similar document for a prompt - Using Cosign Similarity (prompt and embedding)\n",
    "\n",
    "In order to send the prompt and revelant context to the LLM, we look up for similar content from vector database. The method used here is **Codign Similarity** \n",
    "\n",
    "The cosine similarity formula measures the similarity between two vectors by calculating the cosine of the angle between them. It's defined as the dot product of the two vectors divided by the product of their magnitudes (Euclidean norms). The formula can be represented as:\n",
    "```\n",
    "cosine_similarity(A, B) = (A · B) / (||A|| * ||B||)\n",
    "```\n",
    "**Where:**\n",
    "\n",
    "- (A · B): is the dot product of vectors A and B.\n",
    "- ||A|| and ||B|| are the Euclidean norms (magnitudes) of vectors A and B\n",
    "\n",
    "**This formula results in a value between -1 and 1, where:**\n",
    "\n",
    "- A value of 1 indicates that the vectors have the same direction and are perfectly similar.\n",
    "- A value of 0 indicates that the vectors are perpendicular and have no similarity.\n",
    "- A value of -1 indicates that the vectors have opposite directions and are perfectly dissimilar.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "35e8a21f-6cda-4f4f-bd4f-5b4ad7d09279",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets create a function to calculate cosign similarity\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a888ff85-705d-432a-9083-ac32bfe6dcb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosign_similarity(vector1, vector2):\n",
    "    vec1_array = np.array(vector1)\n",
    "    vec2_array = np.array(vector2)\n",
    "    dot_product = np.dot(vec1_array, vec2_array)\n",
    "    magnitude_vec1 = np.linalg.norm(vec1_array)\n",
    "    magnitude_vec2 = np.linalg.norm(vec2_array) \n",
    "    return dot_product/(magnitude_vec1 * magnitude_vec2)\n",
    "\n",
    "#cosign_similarity(vector_db['embeddings'][0],vector_db['embeddings'][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e22074f4-18fa-4bc7-9f0d-8566e51bf9c7",
   "metadata": {},
   "source": [
    "## Step 5: Create prompt for the LLM along with the context emmbedding\n",
    "Lets find similar text (context) from the vector DB for the given prompt by comparing vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "35a7dd0a-21a1-41c1-b515-da282dcbe11b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>identifier</th>\n",
       "      <th>text</th>\n",
       "      <th>embeddings</th>\n",
       "      <th>prompt_similarity_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cricket-news</td>\n",
       "      <td>Legendary India batter Virat Kohli has announc...</td>\n",
       "      <td>[-0.03001970238983631, 0.026122447103261948, 0...</td>\n",
       "      <td>0.038281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>uk-employment-news</td>\n",
       "      <td>The UK's job market has continued to weaken wi...</td>\n",
       "      <td>[0.023377733305096626, 0.07752429693937302, -0...</td>\n",
       "      <td>0.557581</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           identifier                                               text  \\\n",
       "0        cricket-news  Legendary India batter Virat Kohli has announc...   \n",
       "1  uk-employment-news  The UK's job market has continued to weaken wi...   \n",
       "\n",
       "                                          embeddings  prompt_similarity_score  \n",
       "0  [-0.03001970238983631, 0.026122447103261948, 0...                 0.038281  \n",
       "1  [0.023377733305096626, 0.07752429693937302, -0...                 0.557581  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "prompt = \"Has the UK unemployment rate increased or decreased recently?\"\n",
    "\n",
    "# Create text embedding for the prompt\n",
    "embedding_for_prompt = get_text_embedding(prompt)\n",
    "\n",
    "# Find cosign similarity for each item in the vector database and get the most similar text\n",
    "\n",
    "vector_db['prompt_similarity_score'] = vector_db['embeddings'].apply(lambda vec : cosign_similarity(vec, embedding_for_prompt))\n",
    "vector_db\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d23031a8-398f-4919-83b1-4bef8d547544",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the most similar text by comparing the prompt_similarity_score \n",
    "most_similar_text = vector_db.nlargest(1, 'prompt_similarity_score').iloc[0]['text']\n",
    "#most_similar_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "96b6907d-f79d-43ff-9b6a-3a3af8a97e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_prompt = f\"Answer the question based on the context provided.\\n Question: {prompt}\\n And the context: {most_similar_text}\\n\"\n",
    "#full_prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4958f09-7186-4ee1-9b8a-01524788e067",
   "metadata": {},
   "source": [
    "## Step 6: Generate content using LLM \n",
    "\n",
    "LLM Model to use - Meta Llama - `meta.llama3-70b-instruct-v1:0`\n",
    "\n",
    "Lets use https://github.com/nilavalagansugumaran/Nila-AI-ML-Projects/blob/main/bedrock_samples/meta-llama/meta-llama-text-generation.md as a reference to construct the request and generate content using the LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2d810e7b-294f-4dc6-8f39-533c3a197398",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use json module to construct the requets payload\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d8f2ad0b-221f-4362-8851-509d9ce58640",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embed the prompt in Llama 3's instruction format.\n",
    "prompt_for_llm = f\"\"\"\n",
    "<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n",
    "{full_prompt}\n",
    "<|eot_id|>\n",
    "<|start_header_id|>assistant<|end_header_id|>\n",
    "\"\"\"\n",
    "\n",
    "req = json.dumps({\n",
    "    'prompt': prompt_for_llm,\n",
    "    'temperature': 1.0,\n",
    "    'top_p': 1.0,\n",
    "    'max_gen_len': 200\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8b889620-2654-47a0-a8ae-4c09cd33645f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "According to the context, the UK unemployment rate has increased recently, specifically from 4.4% to 4.5% in the January to March period.\n"
     ]
    }
   ],
   "source": [
    "bedrock_runtime = boto3.client(service_name='bedrock-runtime', region_name='us-east-1')\n",
    "response = bedrock_runtime.invoke_model(body=req, modelId='meta.llama3-70b-instruct-v1:0')\n",
    "body = json.loads(response.get('body').read())\n",
    "gen_text = body['generation']\n",
    "print(gen_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
