{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "85cfb99e-08fa-485d-8ee2-a942cc071255",
   "metadata": {},
   "source": [
    "# RAG (Retrieval Augumented Generation) - Example\n",
    "RAG is a mechanism of retrieving and incorporating external information before LLM generates a response. The external information has to be vector embeddings usually stored in a vector database such as pinecore, opensearch etc... This techinique is very cost and time effective comparing with fine tuning model in which the LLM model will need to be re-trained.\n",
    "\n",
    "There are ML models available which helps creating embeddings from text or images or both(multimodel models).\n",
    "\n",
    "In this example, we are going to expore a typical workflow of RAG.\n",
    "\n",
    "- Step 1: Read document for embedding\n",
    "- Step 2: Create embedding using amazon embedding model - amazon.titan-embed-text-v2:0\n",
    "- Step 3: Create a dataframe to store the embeddings (mock vector database)\n",
    "- Step 4: Create prompt for the LLM along with the context emmbedding\n",
    "- Step 5: Generate content using the Meta Llama model - ``"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01001d91-1e1f-4386-8497-b525faaaebd7",
   "metadata": {},
   "source": [
    "## Step 1: Read documents for embedding\n",
    "We will use Pypdf to read a PDF document. For re-usability purpose, lets create a function to read a pdf file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6dfb06d5-9c17-4343-9f61-6992cc95295d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.python.org/simple\n",
      "Requirement already satisfied: pypdf in /Users/nila/Documents/Learning.nosync/AI/Nila-AI-ML-Projects/bedrock_samples/env/lib/python3.13/site-packages (5.5.0)\n"
     ]
    }
   ],
   "source": [
    "# Use pypdf to read PDF document as string\n",
    "# Install pypdf if not exists already\n",
    "!pip install pypdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81afba6e-c88d-4f2e-87f6-7e26beae030a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pypdf import PdfReader\n",
    "\n",
    "#Lets create a function to read PDF pages\n",
    "\n",
    "def as_text(pdf_file_name):\n",
    "    reader = PdfReader(pdf_file_name)\n",
    "    print(f'Number of pages {len(reader.pages)}')\n",
    "    # Lets read only the first page\n",
    "    page = reader.pages[0]\n",
    "    return page.extract_text()\n",
    "\n",
    "#print(as_text('sports_news.pdf'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a87b753f-f10a-47bc-a0bd-a629a491f747",
   "metadata": {},
   "source": [
    "## Step 2: Create embedding using amazon embedding model\n",
    "We are going to use Amazon embedding model - amazon.titan-embed-text-v2:0\n",
    "\n",
    "Request format for the model is as below,\n",
    "```\n",
    "{\n",
    "    \"inputText\": string,\n",
    "    \"dimensions\": int,\n",
    "    \"normalize\": boolean,\n",
    "    \"embeddingTypes\": list\n",
    "}\n",
    "```\n",
    "Response format,\n",
    "```\n",
    "{\n",
    "    \"embedding\": [float, float, ...],\n",
    "    \"inputTextTokenCount\": int,\n",
    "    \"embeddingsByType\": {\"binary\": [int,..], \"float\": [float,...]}\n",
    "}\n",
    "```\n",
    "Reference documentation - https://docs.aws.amazon.com/bedrock/latest/userguide/model-parameters-titan-embed-text.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "358651c6-1838-460a-b41c-19d14933f22d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure AWS environment\n",
    "# Below method is NOT recommended for public sharing or deployments to environments\n",
    "import os\n",
    "\n",
    "#os.environ['AWS_ACCESS_KEY_ID'] = 'your key id'\n",
    "#os.environ['AWS_SECRET_ACCESS_KEY'] = 'your secret'\n",
    "os.environ['AWS_DEFAULT_REGION'] = 'us-east-1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "63d83516-7052-442d-9f79-d0f9e000e3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets use boto3 to connect to bedrock APIs to access the model\n",
    "import boto3\n",
    "# Use json to build the request\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6f9b15a5-7e96-43f0-8539-16cec8ebc3c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For reuseability lets create a function\n",
    "def get_text_embedding(text_for_embedding):\n",
    "    bedrock_runtime = boto3.client(service_name='bedrock-runtime', region_name='us-east-1')\n",
    "    req = json.dumps({'inputText':text_for_embedding})\n",
    "    response = bedrock_runtime.invoke_model(body=req, modelId='amazon.titan-embed-text-v2:0')\n",
    "    response_body = json.loads(response.get('body').read())\n",
    "    return response_body['embedding']\n",
    "#print(get_text_embedding(as_text('sports_news.pdf')))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99ee33dd-7766-4cf4-ab85-d0e08efcc1f7",
   "metadata": {},
   "source": [
    "## Step 3: Create a data frame to store the embeddings (mock vector database)¶\n",
    "In production like environments, the embeddings will be stored in a vector database. For the purpose of demonstration, lets create a mock vector database using pandas dataframe. The dataframe need to have the below,\n",
    "\n",
    "- Identifier/title\n",
    "- Text\n",
    "- Embedding\n",
    "-------------------------------\n",
    "identifier | Text | Embedding\n",
    "-------------------------------\n",
    "       |               |\n",
    "       |               |\n",
    "       |               |       \n",
    "-------------------------------\n",
    "\n",
    "Lets use the functions that we have created on steps 1 and 2 to create the mock vector database.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ff9b33ec-f84a-402c-aef8-a1f380c47135",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ignoring wrong pointing object 6 0 (offset 0)\n",
      "Ignoring wrong pointing object 6 0 (offset 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of pages 1\n",
      "Number of pages 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>identifier</th>\n",
       "      <th>text</th>\n",
       "      <th>embeddings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cricket-news</td>\n",
       "      <td>Legendary India batter Virat Kohli has announc...</td>\n",
       "      <td>[-0.03001970238983631, 0.026122447103261948, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>uk-employment-news</td>\n",
       "      <td>The UK's job market has continued to weaken wi...</td>\n",
       "      <td>[0.023377733305096626, 0.07752429693937302, -0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           identifier                                               text  \\\n",
       "0        cricket-news  Legendary India batter Virat Kohli has announc...   \n",
       "1  uk-employment-news  The UK's job market has continued to weaken wi...   \n",
       "\n",
       "                                          embeddings  \n",
       "0  [-0.03001970238983631, 0.026122447103261948, 0...  \n",
       "1  [0.023377733305096626, 0.07752429693937302, -0...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use pandas to create dataframe\n",
    "import pandas as pd\n",
    "\n",
    "sports_news = as_text('sports_news.pdf')\n",
    "employment_news = as_text('uk-job-market-news.pdf')\n",
    "data = {'identifier':['cricket-news', 'uk-employment-news'],\n",
    "       'text':[sports_news,employment_news],\n",
    "        'embeddings':[get_text_embedding(sports_news), get_text_embedding(employment_news)]\n",
    "       }\n",
    "vector_db = pd.DataFrame(data)\n",
    "vector_db"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "067a079c-d357-4bf0-ab1e-2e7d40204a90",
   "metadata": {},
   "source": [
    "### Cosign Similarity\n",
    "The cosine similarity formula measures the similarity between two vectors by calculating the cosine of the angle between them. It's defined as the dot product of the two vectors divided by the product of their magnitudes (Euclidean norms). The formula can be represented as:\n",
    "```\n",
    "cosine_similarity(A, B) = (A · B) / (||A|| * ||B||)\n",
    "```\n",
    "**Where:**\n",
    "\n",
    "- (A · B): is the dot product of vectors A and B.\n",
    "- ||A|| and ||B|| are the Euclidean norms (magnitudes) of vectors A and B\n",
    "\n",
    "**This formula results in a value between -1 and 1, where:**\n",
    "\n",
    "- A value of 1 indicates that the vectors have the same direction and are perfectly similar.\n",
    "- A value of 0 indicates that the vectors are perpendicular and have no similarity.\n",
    "- A value of -1 indicates that the vectors have opposite directions and are perfectly dissimilar.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a888ff85-705d-432a-9083-ac32bfe6dcb5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
